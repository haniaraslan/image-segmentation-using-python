# -*- coding: utf-8 -*-
"""[Assign2][5467][5591][5369][5497].ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nkpt3n6qw2BU472rXqZ3oH_1H9Yx0Pn8

#Load dataset
[Google drive link to download dataset first](https://drive.google.com/drive/folders/1_a7hEo0xMt_Xv0y24TQzPd9tBXhNY_Ab?usp=sharing)
"""

!unzip data

"""#Imports"""

import os
import cv2
import math
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.io import loadmat
from itertools import product
from sklearn.cluster import KMeans
from sklearn.metrics import precision_score, recall_score, f1_score 
from sklearn.cluster import SpectralClustering

"""#Visualize image



"""

def getImages(n):

  images=[]
  counter=0
  path = '/content/data/images/test'
  
  for imageName in os.listdir(path):
    if counter!=n:
        images.append(imageName.replace('.jpg',''))
        counter+=1

  return images

def displayImage(fileName):
  #Image
  path = '/content/data/images/test'
  imageName = fileName + '.jpg'
  imagePath = os.path.join(path,imageName)
  normalImage = cv2.imread(imagePath)
  normalImage = cv2.cvtColor(normalImage, cv2.COLOR_BGR2RGB)
  plt.figure(figsize=(20,5))
  plt.subplot(1,6,1)
  plt.title('Normal Image')
  plt.imshow(normalImage)
  
  #Ground truth
  path = '/content/data/groundTruth/test'
  imageName = fileName + '.mat'
  imagePath = os.path.join(path,imageName)
  groundTruth = loadmat(imagePath)
  segments = []

  for i in range(5):
    image = np.array(groundTruth['groundTruth'][0][i][0][0][0])
    segments.append(image)
    plt.subplot(1,6,(i+2))
    plt.title('Segment number '+str(i))
    plt.imshow(image)
  plt.show()
  segments = np.array(segments)
  return normalImage,segments

"""#Segmentation using K-means"""

def kmeans_clustering(image,K):

  labels = np.zeros((5,463203))
  dimensions = image.shape
  image = image.reshape((-1, 3))
  image = np.float32(image)

  segmentedImage=np.zeros((len(K),dimensions[0],dimensions[1]))
  idx=0

  for k in K:

    kmeans = KMeans(n_clusters=k, random_state=0).fit(image)
    segmentedImage[idx] = np.array([j for j in kmeans.labels_]).reshape(dimensions[0],dimensions[1])

    # show the image
    plt.title('At k='+str(k)+' clusters (Kmeans clustering)')
    plt.imshow(segmentedImage[idx])
    plt.show()
    idx += 1
    
  return segmentedImage

"""#F-Measure & Conditional Entropy"""

def F_measure(segImg_pred,segments,numberOfClusters,normalizedCut):
  totalAverage=0
  for K, k in zip(numberOfClusters, range(len(segImg_pred))):
    fmeasure_sum=0
    for s in range(len(segments)):
      if normalizedCut:
        segment = cv2.resize(segments[s],None,fx = 0.15,fy = 0.15)
        prec=precision_score(segment.flatten(), segImg_pred[k].flatten(), average='macro',zero_division=1)
        recall=recall_score(segment.flatten(), segImg_pred[k].flatten(), average='macro',zero_division=1) 
      else:
        prec=precision_score(segments[s].flatten(), segImg_pred[k].flatten(), average='macro',zero_division=1)
        recall=recall_score(segments[s].flatten(), segImg_pred[k].flatten(), average='macro',zero_division=1)
      f_measure=(2.0*prec*recall)/(prec+recall)
      fmeasure_sum+=f_measure
      print('F-measure at k:',str(K),' and groundTruth segment:',str(s),' is:',f_measure)
    totalAverage+=fmeasure_sum  
    print('Average at K:',K,' is: ',fmeasure_sum/len(segments))
    print('------------------------------------')
  print('Total Average is: ',totalAverage/(len(numberOfClusters)*len(segments)))
  print('------------------------------------')

def ConditionalEntropy(segmentedImg,groundTruthSegments,numberOfClusters,normalizedCut):
  condEntropyList = []
  averageTotal=0
  for k,image in zip(numberOfClusters,range(len(segmentedImg))):
    prediction = segmentedImg[image].flatten()
    averageCondEntropy = 0
    for groundTruthIamge in range(groundTruthSegments.shape[0]):
      if normalizedCut:
        groundTruth = cv2.resize(groundTruthSegments[groundTruthIamge],None,fx = 0.15,fy = 0.15)
        groundTruth = groundTruth.flatten()
      else:
        groundTruth = groundTruthSegments[groundTruthIamge].flatten()
      predictedLabels = np.unique(prediction)
      predictionIdx = []
      for label in predictedLabels:
        if np.where(prediction == label)[0].size > 0:
          predictionIdx.append(np.where(prediction == label))
      predictionIdx = np.asarray(predictionIdx,dtype=object)
      clusters = []
      for index in range(len(predictedLabels)):
        clusters.append(np.array([groundTruth[idx] for idx in predictionIdx[index]]))
      clusterProbs  = np.unique(prediction, return_counts=True)[1]/prediction.shape[0]
      contengencyTable = pd.crosstab(prediction,groundTruth)
      total = 0
      groundTruthUnique = np.unique(groundTruth)
      for col in groundTruthUnique:
        total += contengencyTable[col]
      contengencyTable["Total"] = total 
      condEntropy = np.zeros(len(clusters))
      for row in range(contengencyTable.shape[0]):
        condEntropyRow = 0
        for col in groundTruthUnique: 
          if contengencyTable[col][row] != 0:
            condEntropyRow += (-contengencyTable[col][row]/contengencyTable["Total"][row])*np.log2(contengencyTable[col][row]/contengencyTable["Total"][row])
        condEntropy[row] = condEntropyRow*clusterProbs[row]
      averageCondEntropy += sum(condEntropy)
      print('Conditional Entropy at k:',k,' and groundTruth segment:',groundTruthIamge,' is:',sum(condEntropy))
    averageTotal+=averageCondEntropy
    averageCondEntropy /= groundTruthSegments.shape[0]
    print('Average at K:',k,' is: ',averageCondEntropy)
    print('------------------------------------')
  print('Total Average is: ',averageTotal/(len(numberOfClusters)*(groundTruthSegments.shape[0])))
  print('------------------------------------')

"""#Step 3 results





"""

images=getImages(50)
k=[3,5,7,9,11]
for imageIdx,imageName in zip(range(len(images)),images):
  print('Image Number:',(imageIdx+1),' Image:',imageName)
  image,segments=displayImage(images[imageIdx])
  segImg=kmeans_clustering(image,k)
  print('---------------Result Evaluation---------------')
  print('F - measure:')
  print('------------------------------------')
  F_measure(segImg,segments,k,False)
  print('Condtional Entropy:')
  print('------------------------------------')
  ConditionalEntropy(segImg,segments,k,False)

"""#Segmentation using Normalized Cut"""

def normalizedCut_clustering(image):
  
  image = cv2.resize(image,None,fx = 0.15,fy = 0.15)  
  dimensions = image.shape
  image = image.reshape((-1, 3))
  image = np.float32(image)

  segmentedImage=np.zeros((1,dimensions[0],dimensions[1]))
  clustering = SpectralClustering(n_clusters=5, affinity ='nearest_neighbors',n_neighbors=5,assign_labels='discretize',random_state=0).fit(image)
  segmentedImage[0] = np.array([j for j in clustering.labels_]).reshape(dimensions[0],dimensions[1])

  # show the image
  plt.title('At k=5 clusters (NC clustering)')
  plt.imshow(segmentedImage[0])
  plt.show()
  return segmentedImage

"""#Step 4 Results - Big picture

>


"""

images=['230098','226060' ,'28083','140088','238025']
k = [5]

for imageIdx,imageName in zip(range(len(images)),images):
  warnings.filterwarnings("ignore")
  print('Image Number:',(imageIdx+1),' Image:',imageName)
  image,segments=displayImage(images[imageIdx])
  segImg=kmeans_clustering(image,k)
  segImgNC = normalizedCut_clustering(image)

  print('---------------Result Evaluation---------------')

  print('F - measure:')
  print('------------------------------------')
  print('At kmeans:')
  F_measure(segImg,segments,k,False)
  print('At normalized cut:')
  F_measure(segImgNC,segments,k,True)

  print('Conditional Entropy:')
  print('------------------------------------')
  print('At kmeans:')
  ConditionalEntropy(segImg,segments,k,False)
  print('At normalized cut:')
  ConditionalEntropy(segImgNC,segments,k,True)

"""#Extra"""

def kmeans_clustering_spatial(image,K):

  dimensions = image.shape
  rgb = image.reshape((-2, 3))
  rgb = np.float32(rgb)
  arr = np.array([
    list(range(dimensions[0]))
    for _ in range(dimensions[1])])
  xs = range(arr.shape[0])
  ys = range(arr.shape[1])
  
  indices = np.array(list(product(ys, xs)))
  indices = np.float32(indices)

  yxrgb = np.append(indices,rgb, axis = 1)
  yxrgb = yxrgb.reshape((-1, 5))
  yxrgb = np.float32(yxrgb)

  segmentedImage=np.zeros((len(K),dimensions[0],dimensions[1]))
  idx=0
  for k in K:
    kmeans = KMeans(n_clusters=k, random_state=0, ).fit(yxrgb)
    segmentedImage[idx] = np.array([j for j in kmeans.labels_]).reshape(dimensions[0],dimensions[1])

    # show the image
    plt.title('At k=5 clusters (kmeans with spatial layout)')
    plt.imshow(segmentedImage[idx])
    plt.show()
    idx += 1
  return segmentedImage

images=['230098','226060','28083','140088','238025']
k = [5]

for imageIdx,imageName in zip(range(len(images)),images):
  warnings.filterwarnings("ignore")

  print('Image Number:',(imageIdx+1),' Image:',imageName)

  image,segments=displayImage(images[imageIdx]) 
  segImg_extra=kmeans_clustering_spatial(image,k)
  segImg=kmeans_clustering(image,k)

  print('---------------Result Evaluation---------------')

  print('F - measure(Kmeans clustering - extra):')
  print('------------------------------------')
  F_measure(segImg_extra,segments,k,False)
  print('F - measure(Kmeans clustering):')
  F_measure(segImg,segments,k,False)

  print('Conditional Entropy(Kmeans clustering - extra):')
  print('------------------------------------')
  ConditionalEntropy(segImg_extra,segments,k,False)
  print('Conditional Entropy(Kmeans clustering):')
  ConditionalEntropy(segImg,segments,k,False)